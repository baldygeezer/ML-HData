{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Without the fancy charts</h1><br>\n",
    "<h2>Load the data</h2>\n",
    "The table shows the top 5 rows...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0    -122.23     37.88                41.0        880.0           129.0   \n1    -122.22     37.86                21.0       7099.0          1106.0   \n2    -122.24     37.85                52.0       1467.0           190.0   \n3    -122.25     37.85                52.0       1274.0           235.0   \n4    -122.25     37.85                52.0       1627.0           280.0   \n\n   population  households  median_income  median_house_value ocean_proximity  \n0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n4       565.0       259.0         3.8462            342200.0        NEAR BAY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def loadData(csvLoc): \n",
    "    return pd.read_csv(csvLoc)\n",
    "dSet=loadData(\"housing.csv\")\n",
    "dSet.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "...and a quick overview for sanity purposes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 10 columns):\nlongitude             20640 non-null float64\nlatitude              20640 non-null float64\nhousing_median_age    20640 non-null float64\ntotal_rooms           20640 non-null float64\ntotal_bedrooms        20433 non-null float64\npopulation            20640 non-null float64\nhouseholds            20640 non-null float64\nmedian_income         20640 non-null float64\nmedian_house_value    20640 non-null float64\nocean_proximity       20640 non-null object\ndtypes: float64(9), object(1)\nmemory usage: 1.6+ MB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dSet.info()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Split the data </h1>\n",
    "We are making a stratified random split for this\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as numpty\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def chopper (data, testPortion):\n",
    "    \n",
    "    #make a categoricl attribute out of median income\n",
    "    data[\"income_cat\"]= pd.cut(data[\"median_income\"],bins=[0., 1.5, 3.0, 4.5, 6., numpty.inf], labels=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    #make arrays of shuffled indices from the dataset that both have the same distribution\n",
    "    split=StratifiedShuffleSplit(n_splits=1,test_size=testPortion, random_state=42)\n",
    "    \n",
    "    #add the rows from each array to the respective output arrays\n",
    "    for train_index, test_index in split.split(data, data[\"income_cat\"]):\n",
    "        testSet=data.loc[test_index]\n",
    "        trainSet=data.loc[train_index]\n",
    "        \n",
    "     #remove the categoric attribute we created earlier   \n",
    "    for set_ in (testSet,trainSet):\n",
    "        set_.drop(\"income_cat\",axis=1,inplace=True)        \n",
    "    #victory!\n",
    "    return testSet, trainSet    \n",
    "            \n",
    "strat_test_set, strat_train_set = chopper(dSet,.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "overview of the training set - looks right to me..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 16512 entries, 17606 to 15775\nData columns (total 10 columns):\nlongitude             16512 non-null float64\nlatitude              16512 non-null float64\nhousing_median_age    16512 non-null float64\ntotal_rooms           16512 non-null float64\ntotal_bedrooms        16354 non-null float64\npopulation            16512 non-null float64\nhouseholds            16512 non-null float64\nmedian_income         16512 non-null float64\nmedian_house_value    16512 non-null float64\nocean_proximity       16512 non-null object\ndtypes: float64(9), object(1)\nmemory usage: 1.4+ MB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "strat_train_set.info()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cleaning data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(16512, 16)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#drop the median house value and copy it into a set of labels before we start cleaning data\n",
    "housing=strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels=strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "#make a Transformer class to add some more attributes\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "rooms_ix,bedrooms_ix, population_ix, households_ix=3,4,5,6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        #claculate the extra attributes\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        #claculate the optional one if needed\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "#set up a pipeline to process the numeric attributes using the new class and others    \n",
    "num_pipe = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),\n",
    "                    ('attribs_adder',CombinedAttributesAdder()),\n",
    "                    ('std_scaler',StandardScaler()),                    \n",
    "                    ])\n",
    "\n",
    "#split off the numeric attributes...\n",
    "housingNumeric = housing.drop(\"ocean_proximity\", axis=1)\n",
    "#...Store the column headings\n",
    "numeric=list(housingNumeric)\n",
    "#...same for the categorical attributes (1 of them)\n",
    "categoric=[\"ocean_proximity\"]\n",
    "\n",
    "#set up the pipeline to output the complete transformation\n",
    "full_pipe = ColumnTransformer([\n",
    "    (\"num\",num_pipe,numeric),\n",
    "    (\"cat\",OneHotEncoder(),categoric),\n",
    "    ])\n",
    "#execute the pipeline to produce prepared training data\n",
    "trainingDataPrepped=full_pipe.fit_transform(housing)\n",
    "trainingDataPrepped.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now to fit a model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "type(housing_labels)\n",
    "type(trainingDataPrepped)\n",
    "trainingDataPrepped \n",
    "linReg=LinearRegression()\n",
    "linReg.fit(trainingDataPrepped,housing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "OK we has dun a AI!<br>\n",
    "now how accurate is it?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "predictions:  [210644.60459286 317768.80697211 210956.43331178  59218.98886849\n 189747.55849879]\nLables:  [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "4709829587.971121"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "exampleData = housing.iloc[:5]\n",
    "exampleLabels = housing_labels.iloc[:5]\n",
    "preppedExamples=full_pipe.transform(exampleData)\n",
    "print(\"predictions: \",linReg.predict(preppedExamples))\n",
    "print(\"Lables: \",list(exampleLabels))\n",
    "\n",
    "predictions = linReg.predict(trainingDataPrepped)\n",
    "linRegMSE = mean_squared_error(housing_labels,predictions)\n",
    "linRegRMSE=np.sqrt(linRegMSE)\n",
    "linRegMSE\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "not brilliant, but better than the book!? <br>\n",
    "Lets try a decision tree..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "dtReg=DecisionTreeRegressor()\n",
    "dtReg.fit(trainingDataPrepped,housing_labels)\n",
    "\n",
    "\n",
    "dtPredictions=dtReg.predict(trainingDataPrepped)\n",
    "dtMSE=mean_squared_error(housing_labels,dtPredictions)\n",
    "dtRMSE=np.sqrt(dtMSE)\n",
    "dtRMSE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bollocks! There is no way it is perfect! There is a whiff of over fitting here<br/>\n",
    "Let's do some cross-validation, i.e. splitting the training set up into smaller training and test sets. \n",
    "We are using k-fold validation which splits the traing data into 10 subsets, using each one in turn for validation and training on the other 9\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Scores: [68727.83857677 66403.6676539  70529.42529971 69289.29044142\n 71539.99347772 75225.57748434 71288.92293203 70401.40948923\n 77459.14781861 69298.78004939]\nMean: 71016.40532231268\nStandard deviation: 3043.647317294521\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Users/bernardroper/.conda/envs/ML-labs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#gets an array of scores mean squared errors\n",
    "scores = cross_val_score(dtReg, trainingDataPrepped, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "#Scikit-Learnâ€™s cross-validation features expect a utility function (greater is better) rather than a cost function (lower is better), \n",
    "# so the scoring function is actually the opposite of the MSE (i.e., a negative value), we compute -scores before calculating the square root.\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def getYerScoresOut(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "getYerScoresOut(tree_rmse_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ok lets do a random forest\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/bernardroper/.conda/envs/ML-labs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "509438859.79480076"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "r_ForestRegressor=RandomForestRegressor()\n",
    "r_ForestRegressor.fit(trainingDataPrepped,housing_labels)\n",
    "rf_Predictions=r_ForestRegressor.predict(trainingDataPrepped)\n",
    "\n",
    "rf_MSE=mean_squared_error(housing_labels,rf_Predictions)\n",
    "rf_RMSE=np.sqrt(rf_MSE)\n",
    "rf_MSE\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so this is different from the book again<br>\n",
    "try putting the prepped data into a data frame\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['longitude',\n 'latitude',\n 'housing_median_age',\n 'total_rooms',\n 'total_bedrooms',\n 'population',\n 'households',\n 'median_income']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "oneHot=OneHotEncoder()\n",
    "oneHot.fit(housing_cat)\n",
    "\n",
    "\n",
    "columns=list(housingNumeric)\n",
    "columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}